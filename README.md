# clavis
Frameworks: Logstash, Beats e Kibana

# ğŸ¦Ÿ Projeto Clavis - Pipeline de Dados de Dengue

Pipeline completo para extraÃ§Ã£o, processamento e anÃ¡lise de dados de dengue do SUS utilizando Elastic Stack.

## ğŸ“‹ VisÃ£o Geral

Este projeto implementa um pipeline de dados para:
- **ExtraÃ§Ã£o**: Coleta dados da API de arboviroses do SUS
- **Processamento**: Limpeza e transformaÃ§Ã£o dos dados via Logstash
- **Armazenamento**: IndexaÃ§Ã£o no Elasticsearch
- **VisualizaÃ§Ã£o**: AnÃ¡lise via Kibana

## ğŸ—ï¸ Arquitetura

```
Python Extractor â†’ Filebeat â†’ Logstash â†’ Elasticsearch â†’ Kibana
```

## ğŸ“ Estrutura de Arquivos

```
clavis_project/
â”œâ”€â”€ extract_ndjson.py          # Extrator de dados da API SUS
â”œâ”€â”€ docker-compose.yml         # OrquestraÃ§Ã£o de containers
â”œâ”€â”€ filebeat.yml              # ConfiguraÃ§Ã£o do Filebeat
â”œâ”€â”€ logstash.conf             # Pipeline de processamento
â”œâ”€â”€ dengue-template.json      # Template de mapeamento Elasticsearch
â”œâ”€â”€ datafiles/                # DiretÃ³rio de dados NDJSON
â”‚   â”œâ”€â”€ dengue_UF_ANO_MES.ndjson
â”‚   â””â”€â”€ dengue_UF_ANO_consolidated.ndjson
â””â”€â”€ logstash_error_logs/      # Logs de erro do Logstash
```

## ğŸš€ ExecuÃ§Ã£o RÃ¡pida

### 1. PrÃ©-requisitos

- Docker e Docker Compose
- Python 3.8+
- Acesso Ã  internet (para API do SUS)

### 2. ExtraÃ§Ã£o de Dados

```bash
# Executar o extrator de dados
python extract_ndjson.py
```

**OpÃ§Ãµes de extraÃ§Ã£o:**
- **Dados consolidados por ano** (recomendado): Gera um arquivo por estado/ano
- **Dados mensais**: Gera arquivos separados por mÃªs

### 3. Executar o Pipeline ELK

```bash
# Subir toda a stack
docker-compose up -d

# Verificar status dos serviÃ§os
docker-compose ps

# Ver logs em tempo real
docker-compose logs -f filebeat
```

### 4. Verificar Dados no Elasticsearch

```powershell
# Ver Ã­ndices criados
curl.exe -X GET "http://localhost:9200/_cat/indices?v"

# Verificar documentos
curl.exe -X GET "http://localhost:9200/dengue-data-*/_search?size=1&pretty"

# Contar documentos
curl.exe -X GET "http://localhost:9200/dengue-data-*/_count?pretty"
```

### 5. Acessar Kibana

Abrir no navegador: http://localhost:5601

## âš™ï¸ ConfiguraÃ§Ã£o

### Elasticsearch
- **Porta**: 9200
- **Ãndice padrÃ£o**: `dengue-data-YYYY.MM.dd`
- **Health Check**: DisponÃ­vel em `http://localhost:9200`

### Kibana
- **Porta**: 5601
- **ConfiguraÃ§Ã£o**: Conecta automaticamente ao Elasticsearch

### Logstash
- **Porta**: 5044
- **Pipeline**: Processa dados NDJSON do Filebeat
- **Template**: Aplica mapeamento customizado para dados de dengue

### Filebeat
- **Input**: Monitora arquivos NDJSON em `./datafiles/`
- **Output**: Envia para Logstash na porta 5044

## ğŸ¯ Funcionalidades do Pipeline

### Processamento de Dados
- âœ… Parse automÃ¡tico de JSON
- âœ… Limpeza de campos desnecessÃ¡rios
- âœ… ConversÃ£o de tipos (datas, nÃºmeros)
- âœ… ValidaÃ§Ã£o de dados
- âœ… Tratamento de erros

### Campos Principais Processados
- **IdentificaÃ§Ã£o**: `id_agravo`, `id_municip`, `sg_uf_not`
- **Datas**: `dt_notific`, `dt_sin_pri`, `dt_encerra`
- **DemogrÃ¡ficos**: `cs_sexo`, `nu_idade_n`, `cs_raca`
- **ClÃ­nicos**: `febre`, `cefaleia`, `mialgia`, `exantema`
- **EvoluÃ§Ã£o**: `classi_fin`, `evolucao`, `hospitaliz`

## ğŸ”§ Troubleshooting

### Problemas Comuns

1. **Elasticsearch nÃ£o sobe**
   ```bash
   docker-compose logs elasticsearch
   # Verificar se hÃ¡ conflito de porta 9200
   ```

2. **Filebeat nÃ£o envia dados**
   ```bash
   docker-compose logs filebeat
   # Verificar permissÃµes dos arquivos .ndjson
   ```

3. **Logstash com erro de parse**
   ```bash
   docker-compose logs logstash
   # Verificar estrutura dos arquivos NDJSON
   ```

### Comandos Ãšteis

```bash
# Reiniciar serviÃ§os especÃ­ficos
docker-compose restart filebeat logstash

# Parar todos os serviÃ§os
docker-compose down

# Ver espaÃ§o em disco dos containers
docker system df

# Limpar dados nÃ£o utilizados
docker system prune
```

### VerificaÃ§Ã£o de SaÃºde

```bash
# Health check do Elasticsearch
curl.exe -X GET "http://localhost:9200/_cluster/health?pretty"

# Stats do Filebeat
docker-compose exec filebeat filebeat test output

# Status do pipeline Logstash
curl.exe -X GET "http://localhost:9600/?pretty"
```

## ğŸ“Š AnÃ¡lise no Kibana

ApÃ³s a ingestÃ£o dos dados:

1. **Criar Index Pattern**:
   - Acessar Stack Management â†’ Index Patterns
   - Criar pattern: `dengue-data-*`

2. **Explorar dados**:
   - Usar Discover para visualizar documentos
   - Criar visualizaÃ§Ãµes em Dashboard
   - Utilizar Lens para anÃ¡lises rÃ¡pidas

3. **Exemplos de anÃ¡lise**:
   - Casos por UF e perÃ­odo
   - DistribuiÃ§Ã£o por sexo e faixa etÃ¡ria
   - EvoluÃ§Ã£o temporal dos casos
   - CorrelaÃ§Ã£o com sintomas

## ğŸ—‚ï¸ Estrutura de Dados

### Arquivos Gerados
- **Formato**: NDJSON (Newline Delimited JSON)
- **CodificaÃ§Ã£o**: UTF-8
- **LocalizaÃ§Ã£o**: `./datafiles/`
- **PadrÃ£o de nome**: `dengue_UF_ANO_consolidated.ndjson`

### Metadados do Pipeline
- `processed_at`: Timestamp de processamento
- `pipeline_version`: VersÃ£o do pipeline
- `data_source`: Fonte dos dados (SUS_Dengue)

## ğŸ“ Notas de Desenvolvimento

### Para Modificar o Pipeline

1. **Alterar processamento**: Editar `logstash.conf`
2. **Modificar mapeamento**: Atualizar `dengue-template.json`
3. **Ajustar extraÃ§Ã£o**: Modificar `extract_ndjson.py`
4. **Reconfigurar coleta**: Ajustar `filebeat.yml`

### Para Adicionar Novos Campos

1. Atualizar o template do Elasticsearch
2. Modificar o pipeline do Logstash
3. Reiniciar a stack

## ğŸ”’ ConsideraÃ§Ãµes de SeguranÃ§a

- Stack executada localmente
- Sem autenticaÃ§Ã£o habilitada (ambiente de desenvolvimento)
- Dados epidemiolÃ³gicos pÃºblicos
- Recomendado usar x-pack security para produÃ§Ã£o

## ğŸ“ Suporte

Em caso de problemas:
1. Verificar logs com `docker-compose logs [serviÃ§o]`
2. Validar estrutura dos arquivos NDJSON
3. Testar conectividade entre serviÃ§os
4. Verificar recursos do sistema (memÃ³ria, disco)

---

**ğŸ“Š Status do Pipeline**: âœ… Operacional  
**ğŸ”„ Ãšltima AtualizaÃ§Ã£o**: Novembro 2024  
**ğŸ› Issues Conhecidos**: Nenhum
